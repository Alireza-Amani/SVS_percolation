{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReadMe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>This notebook</strong> contains the codes for evaluating the performance of the model in terms of different probabilistic and deterministic metrics.</p>\n",
    "\n",
    "<p><strong>The deterministic metrics are:</strong></p>\n",
    "<ul>\n",
    "    <li><em>Mean Bias Error (MBE)</em></li>\n",
    "    <li><em>coefficient of determination (R2)</em></li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>The probabilistic metrics are:</strong></p>\n",
    "<ul>\n",
    "    <li><em>Continuous Ranked Probability Score (CRPS)</em></li>\n",
    "    <li><em>Continuous Ranked Probability Skill Score (CRPSS)</em></li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Python version:</strong> 3.11.3</p>\n",
    "\n",
    "<p><strong>Utilized packages:</strong></p>\n",
    "<ul>\n",
    "    <li><code>numpy (1.24.3)</code></li>\n",
    "    <li><code>pandas (2.0.1)</code></li>\n",
    "    <li><code>matplotlib, seaborn (3.7.1, 0.12.2)</code></li>\n",
    "    <li><code>ensverif (0.1.0)</code></li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Guide to the notebook:</strong></p>\n",
    "\n",
    "<p>Each section is separated by a markdown cell with a title. The sections are:</p>\n",
    "\n",
    "<h3>Imports</h3>\n",
    "<p><strong>Import the required packages and define the helper functions.</strong></p>\n",
    "\n",
    "<h3>Variables</h3>\n",
    "<p><strong>Define the variables used in the notebook.</strong></p>\n",
    "\n",
    "<h3>Read and process data</h3>\n",
    "<p><strong>Read the data and process it into the required format.</strong></p>\n",
    "\n",
    "<h3>Deterministic metrics</h3>\n",
    "<p><strong>Calculate the deterministic metrics.</strong></p>\n",
    "\n",
    "<h3>Probabilistic metrics</h3>\n",
    "<p><strong>Calculate the probabilistic metrics.</strong></p>\n",
    "\n",
    "<h3>Plot the results</h3>\n",
    "<p><strong>Plot the results into bar charts.</strong></p>\n",
    "\n",
    "<p><strong>The notebook is designed to be run from top to bottom.</strong></p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< imports >>> -----------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ensverif as ev\n",
    "\n",
    "# make fonts bold in plots\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< functions >>> ---------------------------------------------------------\n",
    "\n",
    "def calculate_crps(df, num_scenarios=200, ens_columns_prefix='scn_', obs_column='Value'):\n",
    "    \"\"\"\n",
    "    Calculate the Continuous Ranked Probability Score (CRPS) for a given DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing ensemble forecasts and observations.\n",
    "    num_scenarios : int\n",
    "        Number of ensemble scenarios to consider.\n",
    "    ens_columns_prefix : str, optional\n",
    "        Prefix for column names representing ensemble forecasts. Default is 'scn_'.\n",
    "    obs_column : str, optional\n",
    "        Column name representing observations. Default is 'Value'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with the CRPS result.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the ensemble forecasts\n",
    "    ens = df[[ens_columns_prefix + str(i) for i in range(num_scenarios)]]\n",
    "\n",
    "    # Extract the observations\n",
    "    obs = df[obs_column]\n",
    "\n",
    "    # Calculate CRPS\n",
    "    crps_result = ev.crps_hersbach_decomposition(ens, obs)[0]\n",
    "    \n",
    "    # Return the CRPS result as a DataFrame\n",
    "    return pd.DataFrame({'CRPS': [crps_result]})\n",
    "\n",
    "\n",
    "def benchmark_crps(df, ens_num=200, ens_factor=0.25, obs_column='Value'):\n",
    "    \"\"\"\n",
    "    Calculate the benchmark CRPS for a given DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing observations.\n",
    "    ens_num : int\n",
    "        Number of ensemble forecasts to generate.\n",
    "    ens_factor : float\n",
    "        Scaling factor for ensemble forecasts.\n",
    "    obs_column : str, optional\n",
    "        Column name representing observations. Default is 'Value'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with the benchmark CRPS result.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ens_shape = (df.shape[0], ens_num)\n",
    "\n",
    "    # Define the ensemble based on mean and standard deviation\n",
    "    ens_range = np.linspace(\n",
    "        np.nanmean(df[obs_column]) - np.nanstd(df[obs_column]) * ens_factor,\n",
    "        np.nanmean(df[obs_column]) + np.nanstd(df[obs_column]) * ens_factor,\n",
    "        ens_num,\n",
    "        endpoint=True\n",
    "    )\n",
    "\n",
    "    # Generate the ensemble\n",
    "    ens = np.tile(ens_range, ens_shape[0]).reshape(ens_shape)\n",
    "\n",
    "\n",
    "    # Extract the observations\n",
    "    obs = df[obs_column]\n",
    "\n",
    "    # Calculate CRPS\n",
    "    crps_result = ev.crps_hersbach_decomposition(ens, obs)[0]\n",
    "\n",
    "    # Return the CRPS result as a DataFrame\n",
    "    return pd.DataFrame({'Benchmark CRPS': [crps_result]})\n",
    "\n",
    "\n",
    "def get_units(variable, metric):\n",
    "    \"\"\"\n",
    "    Get the units for a given variable and metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    variable : str\n",
    "        Variable name.\n",
    "    metric : str\n",
    "        Metric name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        Units corresponding to the variable and metric combination, or None if not found.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the units using a dictionary\n",
    "    units_mapping = {\n",
    "        (\"Soil Moisture\", \"CRPS\"): \"%\",\n",
    "        (\"Soil Moisture\", \"CRPSS\"): \"-\",\n",
    "        (\"Soil Moisture\", \"r2\"): \"-\",\n",
    "        (\"Soil Moisture\", \"MBE\"): \"%\",\n",
    "        (\"Soil Temperature\", \"CRPS\"): \"°C\",\n",
    "        (\"Soil Temperature\", \"CRPSS\"): \"-\",\n",
    "        (\"Soil Temperature\", \"r2\"): \"-\",\n",
    "        (\"Soil Temperature\", \"MBE\"): \"°C\",\n",
    "        (\"Percolation\", \"CRPS\"): \"mm\",\n",
    "        (\"Percolation\", \"CRPSS\"): \"-\",\n",
    "        (\"Percolation\", \"r2\"): \"-\",\n",
    "        (\"Percolation\", \"MBE\"): \"mm\",\n",
    "        (\"Snow Depth\", \"CRPS\"): \"cm\",\n",
    "        (\"Snow Depth\", \"CRPSS\"): \"-\",\n",
    "        (\"Snow Depth\", \"r2\"): \"-\",\n",
    "        (\"Snow Depth\", \"MBE\"): \"cm\",\n",
    "    }\n",
    "\n",
    "    # Lookup the units in the dictionary\n",
    "    units = units_mapping.get((variable, metric))\n",
    "\n",
    "    return units\n",
    "\n",
    "def get_axis_limits(variable, metric):\n",
    "\n",
    "    # define the units using a dictionary\n",
    "    axis_limits_mapping = {\n",
    "        (\"Soil Moisture\", \"CRPS\"): (0, 10),\n",
    "        (\"Soil Moisture\", \"CRPSS\"): (-0.9, 0.9),\n",
    "        (\"Soil Moisture\", \"r2\"): (0, 1),\n",
    "        (\"Soil Moisture\", \"MBE\"): (-8, 8),\n",
    "        (\"Soil Temperature\", \"CRPS\"): (0, 4),\n",
    "        (\"Soil Temperature\", \"CRPSS\"): (-0.9, 0.9),\n",
    "        (\"Soil Temperature\", \"r2\"): (0, 1),\n",
    "        (\"Soil Temperature\", \"MBE\"): (-4, 4),\n",
    "        (\"Percolation\", \"CRPS\"): (0, 1.0),\n",
    "        (\"Percolation\", \"CRPSS\"): (-0.9, 0.9),\n",
    "        (\"Percolation\", \"r2\"): (0, 1),\n",
    "        (\"Percolation\", \"MBE\"): (-0.7, 0.7),\n",
    "        (\"Snow Depth\", \"CRPS\"): (0, 5),\n",
    "        (\"Snow Depth\", \"CRPSS\"): (-0.9, 0.9),\n",
    "        (\"Snow Depth\", \"r2\"): (0, 1),\n",
    "        (\"Snow Depth\", \"MBE\"): (-4, 4),\n",
    "    }\n",
    "\n",
    "    # lookup the units in the dictionary\n",
    "    axis_limits = axis_limits_mapping.get((variable, metric))\n",
    "\n",
    "    return axis_limits\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< variable definition >>> -----------------------------------------------\n",
    "\n",
    "paths_dict = {\n",
    "\n",
    "    # path to the output of the model runs\n",
    "    # (This is produced by the notebook: ...)\n",
    "    \"svs_output\": Path(\n",
    "        \"./output/DailyAveraged_SVS_outputs.csv\"\n",
    "    ),\n",
    "\n",
    "    # path to percolation observations\n",
    "    \"obs_percolation\": Path(\n",
    "        \"./data/percolation_daily_20180701_20210630.csv\"\n",
    "    ),\n",
    "\n",
    "    # path to soil observations\n",
    "    \"obs_soil\": Path(\n",
    "        \"./data/state_vars_daily_20180701_20210630.csv\"\n",
    "    ),\n",
    "\n",
    "    # path to daily meteo observations\n",
    "    \"obs_meteo\": Path(\n",
    "        \"./data/DailyAveraged_MeteoObs.csv\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "# dates for the evaluation period\n",
    "START_DATE = pd.to_datetime(\"2019-07-01\")\n",
    "END_DATE = pd.to_datetime(\"2021-06-30\")\n",
    "\n",
    "# label for the date column in all of the dataframes\n",
    "DATE_LABEL = \"date\"\n",
    "\n",
    "# SVS layers corresponding to the sensor at 7.5 cm depth\n",
    "svs_layers = [3, 4]\n",
    "\n",
    "# number of ensemble scenarios\n",
    "N_ENS = 200\n",
    "\n",
    "# create winter periods for evaluation of snow depth simulations\n",
    "# 2019-11-01 to 2020-04-01 (inclusive) + 2020-11-01 to 2021-04-01 (inclusive)\n",
    "first_winter = pd.date_range(\"2019-11-01\", \"2020-04-01\", freq=\"D\")\n",
    "second_winter = pd.date_range(\"2020-11-01\", \"2021-04-01\", freq=\"D\")\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< Read Data >>> ------------------------------------------------------------\n",
    "\n",
    "# read the output of the model runs\n",
    "svs_output = pd.read_csv(paths_dict[\"svs_output\"], parse_dates=[DATE_LABEL])\n",
    "\n",
    "# read the observed percolation data\n",
    "obs_percolation = pd.read_csv(paths_dict[\"obs_percolation\"], parse_dates=[DATE_LABEL])\n",
    "\n",
    "# read the observed soil state variables\n",
    "obs_soil = pd.read_csv(paths_dict[\"obs_soil\"], parse_dates=[DATE_LABEL])\n",
    "\n",
    "# read the observed meteorological data (we only need snow depth)\n",
    "obs_meteo = pd.read_csv(paths_dict[\"obs_meteo\"], parse_dates=[DATE_LABEL])\n",
    "\n",
    "\n",
    "# make sure all of the dataframes cover the same period\n",
    "svs_output = svs_output[\n",
    "    (svs_output.date >= START_DATE) & (svs_output.date <= END_DATE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "obs_percolation = obs_percolation[\n",
    "    (obs_percolation.date >= START_DATE) & (obs_percolation.date <= END_DATE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "obs_soil = obs_soil[\n",
    "    (obs_soil.date >= START_DATE) & (obs_soil.date <= END_DATE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "obs_meteo = obs_meteo[\n",
    "    (obs_meteo.date >= START_DATE) & (obs_meteo.date <= END_DATE)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "assert svs_output[DATE_LABEL].nunique() == obs_percolation[DATE_LABEL].nunique() \\\n",
    "    == obs_soil[DATE_LABEL].nunique() == obs_meteo[DATE_LABEL].nunique()\n",
    "\n",
    "\n",
    "# create a single column for soil moisture (%) and soil temperature (°C)\n",
    "soil_moist_label = \"soil_moisture\"\n",
    "svs_output[soil_moist_label] = svs_output[\n",
    "    [F\"WSOIL_{str(layer_nr)}\" for layer_nr in svs_layers]\n",
    "].mean(axis=1) * 100\n",
    "\n",
    "soil_temp_label = \"soil_temperature\"\n",
    "svs_output[soil_temp_label] = svs_output[\n",
    "    [F\"TPSOIL_{str(layer_nr)}\" for layer_nr in svs_layers]\n",
    "].mean(axis=1) - 273.15\n",
    "\n",
    "# change unit of SNODP from m to cm\n",
    "svs_output[\"SNODP\"] *= 100\n",
    "\n",
    "# for consistency, `enclosure` label will be renamed to `Experimental Plot`\n",
    "new_enc_label = \"Experimental Plot\"\n",
    "svs_output = svs_output.rename(columns={\"enclosure\": new_enc_label})\n",
    "\n",
    "# select the columns of interest from the SVS output\n",
    "# \"DRAI\" is the percolation (mm/day)\n",
    "# \"SNODP\" is the snow depth over bare ground and low vegetation (cm)\n",
    "interest_cols = [\n",
    "    DATE_LABEL, new_enc_label, \"member\",\n",
    "    soil_moist_label, soil_temp_label, \"DRAI\", \"SNODP\"\n",
    "] \n",
    "svs_output = svs_output[interest_cols]\n",
    "\n",
    "# create the ensemble average of the SVS output\n",
    "# for each date-enclosure average over the ensemble members\n",
    "svs_ensemble_avg = svs_output.groupby(\n",
    "    [DATE_LABEL, new_enc_label], as_index=False\n",
    ").mean(numeric_only=True)\n",
    "\n",
    "\n",
    "# check if the number of ensemble members is correct\n",
    "assert svs_output.groupby(\n",
    "    [DATE_LABEL, new_enc_label], as_index=False\n",
    ").count()[\"member\"].unique() == [N_ENS], F\"Number of ensemble members is not {N_ENS}!\"\n",
    "\n",
    "\n",
    "# ______________________________________________________________________ <<< >>>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc r2 and mbe for soil moisture \n",
    "determ_moisture = pd.merge(\n",
    "    svs_ensemble_avg.loc[:, [DATE_LABEL, new_enc_label,  soil_moist_label]],\n",
    "    obs_soil.loc[obs_soil[\"Variable\"] == \"Soil Volumetric Water Content\", :],\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    "\n",
    "# for each plot and sensor\n",
    ").groupby([new_enc_label, \"Sensor\"]).apply(\n",
    "    lambda x: pd.Series({\n",
    "        \"r2\": x.loc[:, [soil_moist_label, \"Value\"]].corr().iloc[0, 1] ** 2,\n",
    "        \"mbe_percent\": (x[soil_moist_label] - x[\"Value\"]).mean()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# calc r2 and mbe for soil temperature\n",
    "determ_temp = pd.merge(\n",
    "    svs_ensemble_avg.loc[:, [DATE_LABEL, new_enc_label,  soil_temp_label]],\n",
    "    obs_soil.loc[obs_soil[\"Variable\"] == \"Soil Temperature\", :],\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    "\n",
    "# for each plot and sensor\n",
    ").groupby([new_enc_label, \"Sensor\"]).apply(\n",
    "    lambda x: pd.Series({\n",
    "        \"r2\": x.loc[:, [soil_temp_label, \"Value\"]].corr().iloc[0, 1] ** 2,\n",
    "        \"mbe_degC\": (x[soil_temp_label] - x[\"Value\"]).mean()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# calc r2 and mbe for percolation\n",
    "determ_perc = pd.merge(\n",
    "    svs_ensemble_avg.loc[:, [DATE_LABEL, new_enc_label,  \"DRAI\"]],\n",
    "    obs_percolation,\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    "\n",
    "# for each plot and Lysimeter\n",
    ").groupby([new_enc_label, \"Lysimeter\"]).apply(\n",
    "    lambda x: pd.Series({\n",
    "        \"r2\": x.loc[:, [\"DRAI\", \"Percolation (mm/day)\"]].corr().iloc[0, 1] ** 2,\n",
    "        \"mbe_mm\": (x[\"DRAI\"] - x[\"Percolation (mm/day)\"]).mean()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# calc r2 and mbe for snow depth\n",
    "# only for one plot\n",
    "\n",
    "# Calculate for first winter period\n",
    "determ_snow_first = pd.merge(\n",
    "    svs_ensemble_avg.loc[(svs_ensemble_avg[\"Experimental Plot\"] == \"E1\") & \n",
    "                         (svs_ensemble_avg[DATE_LABEL].isin(first_winter)), \n",
    "                         [DATE_LABEL, \"SNODP\"]],\n",
    "    obs_meteo[[DATE_LABEL, \"Snow depth (cm)\"]],\n",
    "    on=DATE_LABEL, how=\"inner\"\n",
    ")\n",
    "\n",
    "snow_r2_first = determ_snow_first.loc[:, [\"SNODP\", \"Snow depth (cm)\"]].corr().iloc[0, 1] ** 2\n",
    "snow_mbe_first = (determ_snow_first[\"SNODP\"] - determ_snow_first[\"Snow depth (cm)\"]).mean()\n",
    "\n",
    "# Calculate for second winter period\n",
    "determ_snow_second = pd.merge(\n",
    "    svs_ensemble_avg.loc[(svs_ensemble_avg[\"Experimental Plot\"] == \"E1\") & \n",
    "                         (svs_ensemble_avg[DATE_LABEL].isin(second_winter)), \n",
    "                         [DATE_LABEL, \"SNODP\"]],\n",
    "    obs_meteo[[DATE_LABEL, \"Snow depth (cm)\"]],\n",
    "    on=DATE_LABEL, how=\"inner\"\n",
    ")\n",
    "\n",
    "snow_r2_second = determ_snow_second.loc[:, [\"SNODP\", \"Snow depth (cm)\"]].corr().iloc[0, 1] ** 2\n",
    "snow_mbe_second = (determ_snow_second[\"SNODP\"] - determ_snow_second[\"Snow depth (cm)\"]).mean()\n",
    "\n",
    "# Average the metrics\n",
    "average_snow_r2 = (snow_r2_first + snow_r2_second) / 2\n",
    "average_snow_mbe = (snow_mbe_first + snow_mbe_second) / 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# combine all the evaluation metrics into a single DataFrame -------------------\n",
    "\n",
    "# Initiate an empty DataFrame to store the results\n",
    "determ_eval_metrics = pd.DataFrame(columns=['Experimental Plot', 'Variable', 'Sensor/Lysimeter', 'r2', 'MBE'])\n",
    "\n",
    "# Insert evaluation metrics for Soil Moisture\n",
    "for index, row in determ_moisture.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row[new_enc_label]],\n",
    "        'Variable': ['Soil Moisture'],\n",
    "        'Sensor/Lysimeter': [row[\"Sensor\"]],\n",
    "        'r2': [row['r2']],\n",
    "        'MBE': [row['mbe_percent']]\n",
    "    })\n",
    "    determ_eval_metrics = pd.concat([determ_eval_metrics, new_row])\n",
    "\n",
    "# Insert evaluation metrics for Soil Temperature\n",
    "for index, row in determ_temp.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row[new_enc_label]],\n",
    "        'Variable': ['Soil Temperature'],\n",
    "        'Sensor/Lysimeter': [row[\"Sensor\"]],\n",
    "        'r2': [row['r2']],\n",
    "        'MBE': [row['mbe_degC']]\n",
    "    })\n",
    "    determ_eval_metrics = pd.concat([determ_eval_metrics, new_row])\n",
    "\n",
    "# Insert evaluation metrics for Percolation\n",
    "for index, row in determ_perc.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row[new_enc_label]],\n",
    "        'Variable': ['Percolation'],\n",
    "        'Sensor/Lysimeter': [row[\"Lysimeter\"]],\n",
    "        'r2': [row['r2']],\n",
    "        'MBE': [row['mbe_mm']]\n",
    "    })\n",
    "    determ_eval_metrics = pd.concat([determ_eval_metrics, new_row])\n",
    "\n",
    "# Insert evaluation metrics for Snow Depth\n",
    "new_row = pd.DataFrame({\n",
    "    'Experimental Plot': [\"\"],\n",
    "    'Variable': ['Snow Depth'],\n",
    "    'Sensor/Lysimeter': [None],\n",
    "    'r2': [average_snow_r2],\n",
    "    'MBE': [average_snow_mbe]\n",
    "})\n",
    "determ_eval_metrics = pd.concat([determ_eval_metrics, new_row])\n",
    "\n",
    "# Reset the index\n",
    "determ_eval_metrics = determ_eval_metrics.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# remove variables that are not needed anymore\n",
    "del determ_moisture, determ_temp, determ_perc, determ_snow_first, determ_snow_second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore RuntimeWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in divide\")\n",
    "\n",
    "# calc CRPS for soil moisture\n",
    "crps_moisture =( \n",
    "\n",
    "    # merge soil moisture ensemble output with observations\n",
    "    pd.merge(\n",
    "    svs_output.loc[:, [DATE_LABEL, new_enc_label,  soil_moist_label, 'member']],\n",
    "    obs_soil.loc[obs_soil[\"Variable\"] == \"Soil Volumetric Water Content\", [DATE_LABEL, new_enc_label, \"Sensor\", \"Value\"]],\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    ")   \n",
    "    # spread the ensemble members into columns\n",
    "    .pivot_table(index=[DATE_LABEL, new_enc_label, \"Sensor\", \"Value\"], columns=\"member\", values=soil_moist_label)\n",
    "    .sort_index(level=0)\n",
    "    .reset_index()\n",
    "\n",
    "    # for each plot and sensor\n",
    "    .groupby([\"Experimental Plot\", \"Sensor\"])\n",
    "\n",
    "    # calculate the CRPS and benchmark CRPS\n",
    "    .apply(lambda x: pd.concat([\n",
    "        calculate_crps(x, N_ENS), benchmark_crps(x, N_ENS)\n",
    "    ], axis=1))\n",
    "\n",
    "    .reset_index()\n",
    "    .drop(columns=\"level_2\")\n",
    "\n",
    "    # calculate the CRPS skill\n",
    "    .assign(CRPSS=lambda x: 1 - x[\"CRPS\"]/x[\"Benchmark CRPS\"])\n",
    ")\n",
    "\n",
    "# calc CRPS for soil temperature\n",
    "crps_temp =(\n",
    "    # merge soil temperature ensemble output with observations\n",
    "    pd.merge(\n",
    "    svs_output.loc[:, [DATE_LABEL, new_enc_label,  soil_temp_label, 'member']],\n",
    "    obs_soil.loc[obs_soil[\"Variable\"] == \"Soil Temperature\", [DATE_LABEL, new_enc_label, \"Sensor\", \"Value\"]],\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    ")\n",
    "    # spread the ensemble members into columns\n",
    "    .pivot_table(index=[DATE_LABEL, new_enc_label, \"Sensor\", \"Value\"], columns=\"member\", values=soil_temp_label)\n",
    "    .sort_index(level=0)\n",
    "    .reset_index()\n",
    "\n",
    "    # for each plot and sensor\n",
    "    .groupby([\"Experimental Plot\", \"Sensor\"])\n",
    "\n",
    "    # calculate the CRPS and benchmark CRPS\n",
    "    .apply(lambda x: pd.concat([\n",
    "        calculate_crps(x, N_ENS), benchmark_crps(x, N_ENS)\n",
    "    ], axis=1))\n",
    "\n",
    "    .reset_index()\n",
    "    .drop(columns=\"level_2\")\n",
    "\n",
    "    # calculate the CRPS skill\n",
    "    .assign(CRPSS=lambda x: 1 - x[\"CRPS\"]/x[\"Benchmark CRPS\"])\n",
    ")\n",
    "\n",
    "# calc CRPS for percolation\n",
    "crps_perc = (\n",
    "    # merge percolation ensemble output with observations\n",
    "    pd.merge(\n",
    "    svs_output.loc[:, [DATE_LABEL, new_enc_label,  \"DRAI\", 'member']],\n",
    "    obs_percolation.loc[:, [DATE_LABEL, new_enc_label, \"Lysimeter\", \"Percolation (mm/day)\"]],\n",
    "    on=[DATE_LABEL, new_enc_label], how=\"inner\"\n",
    ")\n",
    "    # spread the ensemble members into columns\n",
    "    .pivot_table(index=[DATE_LABEL, new_enc_label, \"Lysimeter\", \"Percolation (mm/day)\"], columns=\"member\", values=\"DRAI\")\n",
    "    .sort_index(level=0)\n",
    "    .reset_index()\n",
    "\n",
    "    # for each plot and lysimeter\n",
    "    .groupby([\"Experimental Plot\", \"Lysimeter\"])\n",
    "\n",
    "    # calculate the CRPS and benchmark CRPS\n",
    "    .apply(lambda x: pd.concat([\n",
    "        calculate_crps(x, N_ENS, obs_column=\"Percolation (mm/day)\"),\n",
    "        benchmark_crps(x, N_ENS, obs_column=\"Percolation (mm/day)\")\n",
    "    ], axis=1))\n",
    "\n",
    "    .reset_index()\n",
    "    .drop(columns=\"level_2\")\n",
    "\n",
    "    # calculate the CRPS skill\n",
    "    .assign(CRPSS=lambda x: 1 - x[\"CRPS\"]/x[\"Benchmark CRPS\"])\n",
    ")\n",
    "\n",
    "# calc CRPS for snow depth\n",
    "\n",
    "# first winter\n",
    "crps_snow_first = (\n",
    "    # merge snow depth ensemble output with observations\n",
    "    pd.merge(\n",
    "    svs_output.loc[\n",
    "        (svs_output[DATE_LABEL].isin(first_winter)) & \n",
    "        (svs_output[new_enc_label] == \"E1\"), \n",
    "        [DATE_LABEL, new_enc_label,  \"SNODP\", 'member']\n",
    "    ],\n",
    "    obs_meteo.loc[:, [DATE_LABEL, \"Snow depth (cm)\"]],\n",
    "    on=[DATE_LABEL], how=\"inner\"\n",
    ")\n",
    "    # spread the ensemble members into columns\n",
    "    .pivot_table(index=[DATE_LABEL, new_enc_label, \"Snow depth (cm)\"], columns=\"member\", values=\"SNODP\")\n",
    "    .sort_index(level=0)\n",
    "    .reset_index()\n",
    "\n",
    "    # calculate the CRPS and benchmark CRPS\n",
    "    .pipe(lambda x: pd.concat([\n",
    "        calculate_crps(x, N_ENS, obs_column=\"Snow depth (cm)\"),\n",
    "        benchmark_crps(x, N_ENS, obs_column=\"Snow depth (cm)\")\n",
    "    ], axis=1))\n",
    "\n",
    "    # calculate the CRPS skill\n",
    "    .assign(CRPSS=lambda x: 1 - x[\"CRPS\"]/x[\"Benchmark CRPS\"])\n",
    ")\n",
    "\n",
    "# second winter\n",
    "crps_snow_second = (\n",
    "    # merge snow depth ensemble output with observations\n",
    "    pd.merge(\n",
    "    svs_output.loc[\n",
    "        (svs_output[DATE_LABEL].isin(second_winter)) &\n",
    "        (svs_output[new_enc_label] == \"E1\"),\n",
    "        [DATE_LABEL, new_enc_label,  \"SNODP\", 'member']\n",
    "    ],\n",
    "    obs_meteo.loc[:, [DATE_LABEL, \"Snow depth (cm)\"]],\n",
    "    on=[DATE_LABEL], how=\"inner\"\n",
    ")\n",
    "    # spread the ensemble members into columns\n",
    "    .pivot_table(index=[DATE_LABEL, new_enc_label, \"Snow depth (cm)\"], columns=\"member\", values=\"SNODP\")\n",
    "    .sort_index(level=0)\n",
    "    .reset_index()\n",
    "\n",
    "    # calculate the CRPS and benchmark CRPS\n",
    "    .pipe(lambda x: pd.concat([\n",
    "        calculate_crps(x, N_ENS, obs_column=\"Snow depth (cm)\"),\n",
    "        benchmark_crps(x, N_ENS, obs_column=\"Snow depth (cm)\")\n",
    "    ], axis=1))\n",
    "\n",
    "    # calculate the CRPS skill\n",
    "    .assign(CRPSS=lambda x: 1 - x[\"CRPS\"]/x[\"Benchmark CRPS\"])\n",
    ")\n",
    "\n",
    "average_snow_crps = (crps_snow_first[\"CRPS\"].values + crps_snow_second[\"CRPS\"].values) / 2\n",
    "average_snow_benchmark = (crps_snow_first[\"Benchmark CRPS\"].values + crps_snow_second[\"Benchmark CRPS\"].values) / 2\n",
    "average_snow_crpss = 1 - average_snow_crps / average_snow_benchmark\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# combine all CRPS dataframes --------------------------------------------------\n",
    "# Initiate an empty DataFrame to store the results\n",
    "crps_eval_metrics = pd.DataFrame(columns=['Experimental Plot', 'Variable', 'Sensor/Lysimeter', 'CRPS', 'CRPSS'])\n",
    "\n",
    "# Insert evaluation metrics for Soil Moisture\n",
    "for index, row in crps_moisture.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row['Experimental Plot']],\n",
    "        'Variable': ['Soil Moisture'],\n",
    "        'Sensor/Lysimeter': [row[\"Sensor\"]],\n",
    "        'CRPS': [row['CRPS']],\n",
    "        'CRPSS': [row['CRPSS']]\n",
    "    })\n",
    "    crps_eval_metrics = pd.concat([crps_eval_metrics, new_row])\n",
    "\n",
    "# Insert evaluation metrics for Soil Temperature\n",
    "for index, row in crps_temp.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row['Experimental Plot']],\n",
    "        'Variable': ['Soil Temperature'],\n",
    "        'Sensor/Lysimeter': [row[\"Sensor\"]],\n",
    "        'CRPS': [row['CRPS']],\n",
    "        'CRPSS': [row['CRPSS']]\n",
    "    })\n",
    "    crps_eval_metrics = pd.concat([crps_eval_metrics, new_row])\n",
    "\n",
    "# Insert evaluation metrics for Percolation\n",
    "for index, row in crps_perc.iterrows():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Experimental Plot': [row['Experimental Plot']],\n",
    "        'Variable': ['Percolation'],\n",
    "        'Sensor/Lysimeter': [row[\"Lysimeter\"]],\n",
    "        'CRPS': [row['CRPS']],\n",
    "        'CRPSS': [row['CRPSS']]\n",
    "    })\n",
    "    crps_eval_metrics = pd.concat([crps_eval_metrics, new_row])\n",
    "\n",
    "# Insert average evaluation metrics for Snow Depth\n",
    "new_row = pd.DataFrame({\n",
    "    'Experimental Plot': [\"\"],\n",
    "    'Variable': ['Snow Depth'],\n",
    "    'Sensor/Lysimeter': [None],\n",
    "    'CRPS': average_snow_crps,\n",
    "    'CRPSS': average_snow_crpss\n",
    "})\n",
    "crps_eval_metrics = pd.concat([crps_eval_metrics, new_row])\n",
    "\n",
    "# Reset the index\n",
    "crps_eval_metrics = crps_eval_metrics.reset_index(drop=True)\n",
    "\n",
    "# remove variables that are not needed anymore\n",
    "del crps_moisture, crps_temp, crps_perc\n",
    "\n",
    "# Combine both dataframes into one for easy plotting\n",
    "df_combined = pd.merge(determ_eval_metrics, crps_eval_metrics, on=['Experimental Plot', 'Variable', 'Sensor/Lysimeter'], how='outer')\n",
    "\n",
    "# average over `Sensor/Lysimeter` for each variable\n",
    "df_combined_ave = df_combined.groupby(['Experimental Plot', 'Variable']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# reset to default warning settings\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting parameters\n",
    "figsize = (11, 11)\n",
    "fontsize = 70\n",
    "\n",
    "dfplot = df_combined_ave.melt(\n",
    "    id_vars=[\"Experimental Plot\", \"Variable\"],\n",
    "    value_vars=[\"CRPS\", \"CRPSS\", \"r2\", \"MBE\"],\n",
    "    var_name=\"Metric\", value_name=\"Value\"\n",
    ").copy()\n",
    "\n",
    "# create 4 colors for the 4 experimental plots\n",
    "colors = sns.color_palette(\"colorblind\", n_colors=4)\n",
    "\n",
    "# create a column with the colors\n",
    "dfplot[\"Color\"] = dfplot[\"Experimental Plot\"].map({\n",
    "    \"E1\": colors[0],\n",
    "    \"E2\": colors[1],\n",
    "    \"E3\": colors[2],\n",
    "    \"\": colors[3]\n",
    "})\n",
    "\n",
    "for vbl in dfplot[\"Variable\"].unique():\n",
    "\n",
    "    for met in dfplot[\"Metric\"].unique():\n",
    "\n",
    "        dfplot2 = dfplot.loc[\n",
    "            (dfplot[\"Variable\"] == vbl) &\n",
    "            (dfplot[\"Metric\"] == met)\n",
    "        ].copy()\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "        # set the figure style\n",
    "        sns.set_style(\"white\")\n",
    "        sns.despine()\n",
    "        ax.grid(False)\n",
    "\n",
    "        # plot the data\n",
    "        xorder = [\"E1\", \"E2\", \"E3\"]\n",
    "        if vbl == \"Snow Depth\":\n",
    "            xorder = [\"\", \"E1\", \"E2\", \"E3\"]\n",
    "\n",
    "        sns.barplot(\n",
    "            data=dfplot2,\n",
    "            x=\"Experimental Plot\", y=\"Value\",\n",
    "            hue=\"Experimental Plot\", palette=dfplot2[\"Color\"].unique(), ax=ax,\n",
    "            errorbar=None, order=xorder, dodge=False,\n",
    "        )\n",
    "\n",
    "       \n",
    "\n",
    "        # add the yvalue as text above each bar\n",
    "    \n",
    "        for p in ax.patches:\n",
    "            ax.annotate(\n",
    "                F\"{p.get_height():.2f}\",\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=fontsize//1.15, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "\n",
    "        # y-axis\n",
    "        yx_lab = F\"{met}\"\n",
    "\n",
    "        # if met is r2, use R superscript 2\n",
    "        if met == \"r2\":\n",
    "            yx_lab = r\"R$^2$\"\n",
    "\n",
    "        if (yx_unit := get_units(vbl, met)) != \"-\":\n",
    "\n",
    "            # if unit is mm, then make it mm divided by day like the latex \\\n",
    "            if yx_unit == \"mm\":\n",
    "                yx_unit = r'$\\frac{mm}{day}$'\n",
    "            \n",
    "            yx_lab = F\"{yx_lab} ({yx_unit})\"\n",
    "        \n",
    "        # add gap between yaxis label and yaxis\n",
    "        ax.set_ylabel(yx_lab, fontsize=fontsize, fontweight='bold', labelpad=1)\n",
    "\n",
    "        # set font size for xticks and yticks; also make bold and black\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "        # no xlabel\n",
    "        ax.set_xlabel(None)\n",
    "\n",
    "        # no yticks\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "\n",
    "        \n",
    "        # if its snow, no xticks\n",
    "        if vbl == \"Snow Depth\":\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "        # no legend\n",
    "        ax.legend([],[], frameon=False)\n",
    "\n",
    "        # set ylim\n",
    "        ylim = get_axis_limits(vbl, met)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        # if met is MBE, then add a thin horizontal line at 0\n",
    "        if met == \"MBE\":\n",
    "            ax.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "\n",
    "        # save path \n",
    "        spath = Path(F\"./output/figures/{vbl}_{met}.jpg\")\n",
    "        # plt.savefig(spath, dpi=600, bbox_inches='tight', pad_inches=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        # raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
